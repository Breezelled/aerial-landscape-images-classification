import torch
import torch.nn as nn
from transformers import ViTModel, ViTImageProcessor
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import cv2

# -----------------------------
# æ¨¡åž‹å®šä¹‰ï¼ˆä¸Žè®­ç»ƒæ—¶ä¸€è‡´ï¼‰
# -----------------------------
class ViTForImageClassification(nn.Module):
    def __init__(self, num_classes):
        super(ViTForImageClassification, self).__init__()
        self.vit = ViTModel.from_pretrained(
            "google/vit-base-patch16-224-in21k",
            output_attentions=True  # å¿…é¡»å¯ç”¨æ³¨æ„åŠ›è¾“å‡º
        )
        self.classifier = nn.Linear(self.vit.config.hidden_size, num_classes)

    def forward(self, pixel_values):
        outputs = self.vit(pixel_values=pixel_values)
        cls_token = outputs.last_hidden_state[:, 0]
        logits = self.classifier(cls_token)
        return logits, outputs.attentions  # åŒæ—¶è¿”å›ž logits å’Œ attentions

# -----------------------------
# åŠ è½½æ¨¡åž‹å’Œ checkpoint
# -----------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

num_classes = 15
model = ViTForImageClassification(num_classes=num_classes).to(device)
checkpoint = torch.load("vit_checkpoint.pth", map_location=device)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# -----------------------------
# åŠ è½½å›¾åƒå¹¶é¢„å¤„ç†
# -----------------------------
image_path = "../Aerial_Landscapes/Airport/004.jpg"  # ðŸ” æ›¿æ¢ä¸ºä½ æƒ³è¦å¯è§†åŒ–çš„å›¾åƒè·¯å¾„
image = Image.open(image_path).convert("RGB")

processor = ViTImageProcessor.from_pretrained("google/vit-base-patch16-224-in21k")
inputs = processor(images=image, return_tensors="pt").to(device)

# -----------------------------
# é¢„æµ‹ç±»åˆ« & èŽ·å–æ³¨æ„åŠ›
# -----------------------------
with torch.no_grad():
    logits, attentions = model(pixel_values=inputs['pixel_values'])
    probs = torch.softmax(logits, dim=1)
    pred_class = torch.argmax(probs, dim=1).item()

print(f"âœ… Predicted class index: {pred_class}")
print("ðŸ” Class probabilities:", probs.squeeze().cpu().numpy())

# -----------------------------
# å¯è§†åŒ–æœ€åŽä¸€å±‚ [CLS] æ³¨æ„åŠ›
# -----------------------------
attn = attentions[-1][0]        # shape: [heads, tokens, tokens]
avg_attn = attn.mean(0)         # shape: [tokens, tokens]
cls_attn = avg_attn[0, 1:]      # shape: [196] (CLS -> patches)

# reshape + å½’ä¸€åŒ– + ä¸Šé‡‡æ ·
attn_map = cls_attn.reshape(14, 14).cpu().numpy()
attn_map = (attn_map - attn_map.min()) / (attn_map.max() - attn_map.min())
attn_map_resized = cv2.resize(attn_map, (224, 224))

# æ˜¾ç¤ºçƒ­åŠ›å›¾
resized_img = image.resize((224, 224))
plt.imshow(resized_img)
plt.imshow(attn_map_resized, cmap='jet', alpha=0.5)
plt.title(f"Predicted Class Index: {pred_class}")
plt.axis('off')
plt.savefig('attention_map.png')
# plt.show()
