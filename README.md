# Aerial Landscape Images Classification

### üìå Overview
This is the SkyView aerial image classification project. The goal is to leverage recent advances in pretraining, multimodal learning, and representation learning to build explainable and transferable systems. And also compare with traditional methods like ResNet and ML methods.

Including:

- **Traditional machine learning models**
- **Resnet**
- **ViT**
- **Zero-shot classification using CLIP**, which aligns images and natural language prompts.
- **CLIP fine-tuning using RSICD**, a captioned remote sensing dataset, to enhance domain alignment.
- **Linear probing with DINOv2 and BigEarthNet-pretrained ViT**, to assess feature quality for remote sensing imagery.

All experiments are built around the SkyView dataset, and results from this section contribute to the overall understanding of advanced methods in remote sensing scene classification.

---

### üìÅ Datasets

#### 1. SkyView (Main Task Dataset)
- 15 scene categories (e.g. Forest, River, City, Mountain)
- 800 images per class
- [Kaggle Link](https://www.kaggle.com/datasets/ankit1743/skyview-an-aerial-landscape-dataset)

#### 2. RSICD (for CLIP Fine-tuning)
- Each image annotated with 5 natural language captions
- Enables training vision-language models on remote sensing images
- [RSICD Dataset](https://github.com/201528014227051/RSICD_optimal)

#### 3. BigEarthNet v2.0 (for DINOv2 Finetuneing)
- Over 500k Sentinel-2 image patches
- High semantic overlap with SkyView classes
- [BigEarthNet Website](https://bigearth.net)

---

### üß† Methods

#### üîπ CLIP Zero-shot Classification
- Use OpenAI's CLIP to match SkyView images with class prompts
- Prompts like: `"A satellite image of a {label}"`
- Outputs top-k predicted labels based on image-text similarity
- ‚úÖ *Interpretable and no training required*

#### üîπ CLIP Fine-tuned on RSICD
- Fine-tune CLIP image encoder using image-caption pairs from RSICD
- Each image paired with 5 caption variations
- Improve alignment for aerial scenes with remote sensing domain captions
- ‚úÖ *Improves CLIP's performance on satellite image semantics*

#### üîπ DINOv2 + Linear Probing
- Use `vit_base_patch8_224-s2-v0.1.1` pretrained on BigEarthNet
- Freeze ViT weights and extract image embeddings for SkyView
- Train Logistic Regression or SVM for classification
- ‚úÖ *Evaluates quality of semantic visual features learned from remote sensing*

#### üîπ Resnet50 + image mask + Linear Probing
- Use resnet50 pretrained on ImageNet
- Extract features from masked remote sensing images (e.g., using SAM2-generated masks)
- Freeze ResNet-50 weights and use extracted features for classification
- ‚úÖ *Evaluates the effectiveness of masked image features in remote sensing classification*


#### üîπ Resnet50 + image mask + Fine tuned
- Use resnet50 pretrained on ImageNet
- Extract features from masked remote sensing images (e.g., using SAM2-generated masks)
- Fine-tune all weights jointly with the classifier head
- ‚úÖ *Evaluates the effectiveness of masked image features in remote sensing classification*
---

### üî¨ Experiments & Results


| Model                                 | Fine-tuned? | Method         | Acc@1 | Acc@3 | Acc@5 | Precision | Recall | F1    |
| ------------------------------------- | ----------- | -------------- | ----- | ----- | ----- | --------- | ------ | ----- |
| CLIP (ViT-B/32)                       | ‚ùå No        | Zero-shot      | 78.44 | 94.91 | 98.66 | 80.85     | 78.44  | 77.33 |
| CLIP (Fine-tuned w/ RSICD)            | ‚úÖ Yes       | Zero-shot      | 90.56 | 98.66 | 99.66 | 91.22     | 90.56  | 90.45 |
| ViT (BigEarthNet-S2)                  | ‚ùå No        | Linear probing | TBD   |       |       |           |        |       |
| DINOv2 (Fine-tuned w/ BigEarthNet-S2) | ‚úÖ Yes       | Linear probing | TBD   |       |       |           |        |       |
| Resnet50 (linearprobe on mask)        | ‚ùå No        | Linear probing | 89.54 | 98.42 | 99.42 | 89.69     | 89.67  | 89.65 |
| Resnet50 (finetune on mask)           | ‚úÖ Yes       | Linear probing | 97.04 | 99.71 | 99.92 | 97.09     | 97.09  | 97.08 |

> ‚ö†Ô∏è TODO: Replace TBD with final experimental results

---

### üß† Explainability & Visualization
- **CLIP**: Top-k textual predictions show model reasoning
- **CLIP + GradCAM**: Visualize which region contributed to decision
- **DINOv2**: Feature embedding visualized using t-SNE / PCA to show class clustering

---

### üìà Evaluation Metrics
- Accuracy, Precision, Recall, F1-Score
- Per-class performance analysis
- Confusion matrix and feature distribution plots

---

### üìÇ Project Structure
```
project/
‚îú‚îÄ‚îÄ data/                  # SkyView, RSICD, BigEarthNet subsets
‚îú‚îÄ‚îÄ models/                # CLIP, DINOv2, ViT models...
‚îú‚îÄ‚îÄ scripts/               # Shell scripts for feature extraction, training, evaluation
‚îú‚îÄ‚îÄ utils/                 # Utility functions (mask generator...)
‚îú‚îÄ‚îÄ results/               # Visualizations, confusion matrix, metrics...
‚îú‚îÄ‚îÄ README.md              # This file
```

> ‚ö†Ô∏è TODO: Replace structure example
---

### ‚öôÔ∏è How to Run

```bash
```

> ‚ö†Ô∏è TODO: Add running code

---

### üîó External Resources
- **CLIP**: [Code](https://github.com/openai/CLIP) | [Paper](https://arxiv.org/abs/2103.00020)
- **DINOv2**: [Code](https://github.com/facebookresearch/dinov2) | [Paper](https://arxiv.org/abs/2304.07193)
- **BigEarthNet v2.0**: [Website](https://bigearth.net) | [Paper](https://arxiv.org/abs/2407.03653)
- **RSICD Dataset**: [Code](https://github.com/201528014227051/RSICD_optimal) | [Paper](https://arxiv.org/abs/1712.07835)
- **SAM2**: [Code](https://github.com/facebookresearch/sam2.git) | [Paper](https://arxiv.org/abs/2408.00714)

---

